# ğŸ“Œ Step 1: Setup
!pip install -q tf2onnx
!pip install -q onnxruntime

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras import layers, models, callbacks
from google.colab import drive

# ğŸ“Œ Step 2: Mount Google Drive
drive.mount('/content/drive')

# Define paths
data_path = '/content/drive/MyDrive/emg_data'  # Update if needed
log_dir = "/content/logs"

# ğŸ“Œ Step 3: Load and Preprocess EMG Data
activities = ['sitting', 'standing', 'walking']
emg_data, labels = [], []

for activity in activities:
    file_path = os.path.join(data_path, f'{activity}.csv')
    df = pd.read_csv(file_path)
    scaler = MinMaxScaler()
    norm_data = scaler.fit_transform(df.values)
    emg_data.append(norm_data)
    labels.append(np.full((norm_data.shape[0],), activity))

X = np.concatenate(emg_data, axis=0)
y = np.concatenate(labels, axis=0)
X = X.reshape((X.shape[0], X.shape[1], 1))

# ğŸ“Œ Step 4: Autoencoder for Denoising
def build_autoencoder(input_shape):
    inputs = layers.Input(shape=input_shape)
    x = layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)
    x = layers.MaxPooling1D(2, padding='same')(x)
    x = layers.Conv1D(32, 3, activation='relu', padding='same')(x)
    encoded = layers.MaxPooling1D(2, padding='same')(x)

    x = layers.Conv1D(32, 3, activation='relu', padding='same')(encoded)
    x = layers.UpSampling1D(2)(x)
    x = layers.Conv1D(64, 3, activation='relu', padding='same')(x)
    x = layers.UpSampling1D(2)(x)
    decoded = layers.Conv1D(1, 3, activation='sigmoid', padding='same')(x)

    return models.Model(inputs, decoded)

autoencoder = build_autoencoder((X.shape[1], 1))
autoencoder.compile(optimizer='adam', loss='mse')

tensorboard_cb = callbacks.TensorBoard(log_dir=log_dir + "/autoencoder", histogram_freq=1)
autoencoder.fit(X, X, epochs=30, batch_size=64, shuffle=True, callbacks=[tensorboard_cb])

denoised_X = autoencoder.predict(X)

# ğŸ“Œ Step 5: U-Net + Conformer Model
def conformer_block(x, num_heads, ff_dim):
    attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=ff_dim)(x, x)
    x = layers.Add()([x, attn])
    x = layers.LayerNormalization()(x)
    ffn = layers.Dense(ff_dim, activation='relu')(x)
    ffn = layers.Dense(x.shape[-1])(ffn)
    return layers.LayerNormalization()(layers.Add()([x, ffn]))

def build_unet_conformer(input_shape):
    inputs = layers.Input(shape=input_shape)
    c1 = layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)
    p1 = layers.MaxPooling1D(2)(c1)

    c2 = layers.Conv1D(128, 3, activation='relu', padding='same')(p1)
    p2 = layers.MaxPooling1D(2)(c2)

    b = conformer_block(p2, num_heads=4, ff_dim=128)

    u1 = layers.UpSampling1D(2)(b)
    u1 = layers.Concatenate()([u1, c2])
    c3 = layers.Conv1D(128, 3, activation='relu', padding='same')(u1)

    u2 = layers.UpSampling1D(2)(c3)
    u2 = layers.Concatenate()([u2, c1])
    c4 = layers.Conv1D(64, 3, activation='relu', padding='same')(u2)

    output = layers.Conv1D(1, 1, activation='linear')(c4)

    return models.Model(inputs, output)

unet_conformer = build_unet_conformer((X.shape[1], 1))
unet_conformer.compile(optimizer='adam', loss='mse')

tensorboard_cb2 = callbacks.TensorBoard(log_dir=log_dir + "/unet_conformer", histogram_freq=1)
unet_conformer.fit(denoised_X, X, epochs=30, batch_size=64, shuffle=True, callbacks=[tensorboard_cb2])

# ğŸ“Œ Step 6: Evaluation
predicted = unet_conformer.predict(denoised_X)
mse = mean_squared_error(X.flatten(), predicted.flatten())
r2 = r2_score(X.flatten(), predicted.flatten())
print(f"ğŸ” Evaluation: MSE = {mse:.4f}, R2 = {r2:.4f}")

# ğŸ“Œ Step 7: Export to ONNX
import tf2onnx
onnx_model_path = "/content/emg_unet_conformer.onnx"
spec = (tf.TensorSpec((None, X.shape[1], 1), tf.float32),)
model_proto, _ = tf2onnx.convert.from_keras(unet_conformer, input_signature=spec, output_path=onnx_model_path)
print(f"âœ… ONNX model saved to {onnx_model_path}")

# ğŸ“Œ Step 8: Export to TFLite
tflite_model_path = "/content/emg_unet_conformer.tflite"
converter = tf.lite.TFLiteConverter.from_keras_model(unet_conformer)
tflite_model = converter.convert()
with open(tflite_model_path, "wb") as f:
    f.write(tflite_model)
print(f"âœ… TFLite model saved to {tflite_model_path}")

# ğŸ“Œ Optional: Download or move to Google Drive
!cp /content/emg_unet_conformer.onnx /content/drive/MyDrive/
!cp /content/emg_unet_conformer.tflite /content/drive/MyDrive/
